{
 "cells": [
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# 플랜\n",
    "## 1. 전처리\n",
    "1. 이상치 제거\n",
    "2. 차원축소\n",
    "    1. feature selection\n",
    "        - 'repair_cost'\n",
    "        - 'insure_cost'\n",
    "        - 'repair_cost','insure_cost'\n",
    "    2. PCA 할 feature 선택 \\\n",
    "       여러 feature를 선형조합하여 잠재변수(latent variable)를 만들 수 있다면 선택 가능\n",
    "       - 사고관련 feature\n",
    "4. 더미화\n",
    "    - 샘플링과 더미화 split의 순서가?\n",
    "    - Q)더미화를 하고 샘플링을 하면 카테고리 데이터가 오염될 수 있지 않은가?\n",
    "3. train_test_split\n",
    "    - 샘플링 전에 나눠져야 하는데?\n",
    "3. sampling (oversampling)\n",
    "    - SMOTE\n",
    "    - ADASYM\n",
    "    - RandomOverSampling\n",
    "\n",
    "## 2. 학습\n",
    "여러번 할거니 함수를 만들면서 해보자\n",
    "1. 모델 고르기\n",
    "2. 성능평가\n",
    "3. 학습\n",
    "3. CV\n",
    "4. pipeline ?\n",
    "    \n",
    "## 3. try\n",
    "1. 조건을 바꿔가며 시도\n",
    "2. 함수 개선?"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 65,
   "metadata": {
    "collapsed": true
   },
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "<class 'pandas.core.frame.DataFrame'>\n",
      "RangeIndex: 16000 entries, 0 to 15999\n",
      "Data columns (total 25 columns):\n",
      " #   Column                 Non-Null Count  Dtype  \n",
      "---  ------                 --------------  -----  \n",
      " 0   fraud_YN               16000 non-null  int64  \n",
      " 1   car_model              16000 non-null  int64  \n",
      " 2   sharing_type           16000 non-null  int64  \n",
      " 3   age_group              16000 non-null  int64  \n",
      " 4   has_previous_accident  16000 non-null  int64  \n",
      " 5   cumulative_use_count   16000 non-null  int64  \n",
      " 6   b2b                    16000 non-null  int64  \n",
      " 7   accident_ratio         16000 non-null  int64  \n",
      " 8   pf_type                16000 non-null  int64  \n",
      " 9   socarpass              16000 non-null  int64  \n",
      " 10  socarsave              16000 non-null  int64  \n",
      " 11  start_hour             16000 non-null  int64  \n",
      " 12  duration               16000 non-null  int64  \n",
      " 13  accident_hour          16000 non-null  int64  \n",
      " 14  repair_cost            16000 non-null  float64\n",
      " 15  insure_cost            16000 non-null  int64  \n",
      " 16  accident_location      16000 non-null  int64  \n",
      " 17  car_part1              16000 non-null  int64  \n",
      " 18  car_part2              16000 non-null  int64  \n",
      " 19  repair_cnt             16000 non-null  int64  \n",
      " 20  acc_type1              16000 non-null  int64  \n",
      " 21  insurance_site_aid_YN  16000 non-null  int64  \n",
      " 22  police_site_aid_YN     16000 non-null  int64  \n",
      " 23  total_prsn_cnt         16000 non-null  int64  \n",
      " 24  test_set               16000 non-null  int64  \n",
      "dtypes: float64(1), int64(24)\n",
      "memory usage: 3.1 MB\n"
     ]
    }
   ],
   "source": [
    "df = pd.read_csv('./insurance_fraud_detect_data.csv')\n",
    "df.info()"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# -- Base --"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## 1. 전처리"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### 1-1. 이상치 제거"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "## None"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### 1-2. 차원축소\n",
    "#### feature selection"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "## None"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "#### PCA"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "## None"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### 1-3. train test split"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 42,
   "metadata": {},
   "outputs": [],
   "source": [
    "from sklearn.model_selection import train_test_split"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 66,
   "metadata": {},
   "outputs": [],
   "source": [
    "def train_valid_test_split(df, test_size=0.2, random_state=13):\n",
    "    train_set = df[df['test_set'] == 0]\n",
    "    test_set = df[df['test_set'] == 1]\n",
    "\n",
    "    train_set = train_set.drop('test_set', axis=1)\n",
    "    test_set = test_set.drop('test_set', axis=1)\n",
    "\n",
    "    X = train_set.drop('fraud_YN', axis=1)\n",
    "    y = train_set['fraud_YN']\n",
    "\n",
    "    X_train, X_test, y_train, y_test = train_test_split(X, y, test_size=test_size, random_state=random_state, stratify=y)\n",
    "    X_eval, y_eval = test_set.drop('fraud_YN', axis=1), test_set['fraud_YN']\n",
    "    \n",
    "    print('y_train : ', np.unique(y_train, return_counts=True))\n",
    "    print('y_test :', np.unique(y_test, return_counts=True))\n",
    "    print('y_eval :', np.unique(y_eval, return_counts=True))\n",
    "    \n",
    "    return X_train, X_test, y_train, y_test, X_eval, y_eval"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 67,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "y_train :  (array([0, 1]), array([10276,    27]))\n",
      "y_test : (array([0, 1]), array([2569,    7]))\n",
      "y_eval : (array([0, 1]), array([3114,    7]))\n"
     ]
    }
   ],
   "source": [
    "X_train, X_test, y_train, y_test, X_eval, y_eval = train_valid_test_split(df)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### 1-3. sampling"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "## None"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### 1-4. dummy"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 70,
   "metadata": {},
   "outputs": [],
   "source": [
    "def train_valid_test_dummy(X_train, X_test, X_eval, features=None):\n",
    "    X_train_1hot = pd.get_dummies(X_train, columns=features)\n",
    "    X_test_1hot = pd.get_dummies(X_test, columns=features)    \n",
    "    X_eval_1hot = pd.get_dummies(X_eval, columns=features)  \n",
    "    \n",
    "    return X_train_1hot, X_test_1hot, X_eval_1hot"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 72,
   "metadata": {
    "scrolled": true
   },
   "outputs": [
    {
     "data": {
      "text/plain": [
       "((10303, 75), (2576, 75), (3121, 75))"
      ]
     },
     "execution_count": 72,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "features = df.columns.drop(['fraud_YN', 'accident_ratio', 'repair_cost', 'insure_cost', 'repair_cnt', 'test_set'])\n",
    "X_train_1hot, X_test_1hot, X_eval_1hot = train_valid_test_dummy(X_train, X_test, X_eval, features=features)\n",
    "X_train_1hot.shape, X_test_1hot.shape, X_eval_1hot.shape"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## 2. 학습"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### 2-1. model\n",
    "- Logistic Regression\n",
    "- Decision Tree\n",
    "- Random Forest\n",
    "- LightGBM"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 38,
   "metadata": {},
   "outputs": [],
   "source": [
    "from sklearn.linear_model import LogisticRegression\n",
    "from sklearn.tree import DecisionTreeClassifier\n",
    "from sklearn.ensemble import RandomForestClassifier\n",
    "from lightgbm import LGBMClassifier"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 78,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "['LogisticReg', 'DecisionTree', 'RandomForest', 'LightGBM']"
      ]
     },
     "execution_count": 78,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "models = [('LogisticReg', LogisticRegression(random_state=13, solver='liblinear')),\n",
    "          ('DecisionTree', DecisionTreeClassifier(random_state=13, max_depth=4)),\n",
    "          ('RandomForest', RandomForestClassifier(random_state=13, n_jobs=-1, n_estimators=100)),\n",
    "          ('LightGBM', LGBMClassifier(n_estimators=1000, num_leaves=64, n_jobs=-1, boost_from_average=False))]\n",
    "\n",
    "model_names = [model[0] for model in models]\n",
    "model_names"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### 2-2. 성능평가"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 40,
   "metadata": {},
   "outputs": [],
   "source": [
    "from sklearn.metrics import accuracy_score, precision_score, recall_score, f1_score, roc_auc_score, confusion_matrix"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 82,
   "metadata": {},
   "outputs": [],
   "source": [
    "def get_clf_eval(y_test, pred):\n",
    "    acc = accuracy_score(y_test, pred)\n",
    "    pre = precision_score(y_test, pred)\n",
    "    rec = recall_score(y_test, pred)\n",
    "    f1 = f1_score(y_test, pred)\n",
    "    auc = roc_auc_score(y_test, pred)\n",
    "    \n",
    "    return acc, pre, rec, f1, auc\n",
    "\n",
    "def print_clf_eval(y_test, pred):\n",
    "    confusion = confusion_matrix(y_test, pred)\n",
    "    acc, pre, rec, f1, auc = get_clf_eval(y_test, pred)\n",
    "    \n",
    "    print('=> confusion matrix')\n",
    "    print(confusion)\n",
    "    print('======================')\n",
    "    \n",
    "    print('Accurary: {0:.4f}, Precision: {1:.4f}'.format(acc, pre))\n",
    "    print('Recall: {0:.4f}, F1: {1:.4f}, AUC:{2: .4f}'.format(rec, f1, auc))\n",
    "    \n",
    "def get_result(model, X_train, y_train, X_test, y_test):\n",
    "    model.fit(X_train, y_train)\n",
    "    pred = model.predict(X_test)\n",
    "    \n",
    "    return get_clf_eval(y_valid, pred)\n",
    "\n",
    "def get_result_pd(models, model_names, X_train, y_train, X_test, y_test):\n",
    "    col_names = ['accuracy', 'precision', 'recall', 'f1', 'roc_auc']\n",
    "    tmp = []\n",
    "    \n",
    "    for model in models:\n",
    "        tmp.append(get_result(model[1], X_train, y_train, X_test, y_test))\n",
    "        \n",
    "    return pd.DataFrame(tmp, columns=col_names, index=model_names)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### 2-3. 학습"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 79,
   "metadata": {},
   "outputs": [],
   "source": [
    "import time"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 83,
   "metadata": {},
   "outputs": [
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "/Users/dockyum/opt/anaconda3/lib/python3.8/site-packages/sklearn/metrics/_classification.py:1245: UndefinedMetricWarning: Precision is ill-defined and being set to 0.0 due to no predicted samples. Use `zero_division` parameter to control this behavior.\n",
      "  _warn_prf(average, modifier, msg_start, len(result))\n",
      "/Users/dockyum/opt/anaconda3/lib/python3.8/site-packages/sklearn/metrics/_classification.py:1245: UndefinedMetricWarning: Precision is ill-defined and being set to 0.0 due to no predicted samples. Use `zero_division` parameter to control this behavior.\n",
      "  _warn_prf(average, modifier, msg_start, len(result))\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Fit time : 1.3417472839355469\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "/Users/dockyum/opt/anaconda3/lib/python3.8/site-packages/sklearn/metrics/_classification.py:1245: UndefinedMetricWarning: Precision is ill-defined and being set to 0.0 due to no predicted samples. Use `zero_division` parameter to control this behavior.\n",
      "  _warn_prf(average, modifier, msg_start, len(result))\n"
     ]
    },
    {
     "data": {
      "text/html": [
       "<div>\n",
       "<style scoped>\n",
       "    .dataframe tbody tr th:only-of-type {\n",
       "        vertical-align: middle;\n",
       "    }\n",
       "\n",
       "    .dataframe tbody tr th {\n",
       "        vertical-align: top;\n",
       "    }\n",
       "\n",
       "    .dataframe thead th {\n",
       "        text-align: right;\n",
       "    }\n",
       "</style>\n",
       "<table border=\"1\" class=\"dataframe\">\n",
       "  <thead>\n",
       "    <tr style=\"text-align: right;\">\n",
       "      <th></th>\n",
       "      <th>accuracy</th>\n",
       "      <th>precision</th>\n",
       "      <th>recall</th>\n",
       "      <th>f1</th>\n",
       "      <th>roc_auc</th>\n",
       "    </tr>\n",
       "  </thead>\n",
       "  <tbody>\n",
       "    <tr>\n",
       "      <th>LogisticReg</th>\n",
       "      <td>0.997283</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.500000</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>DecisionTree</th>\n",
       "      <td>0.996894</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.499805</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>RandomForest</th>\n",
       "      <td>0.997283</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.500000</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>LightGBM</th>\n",
       "      <td>0.997283</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.500000</td>\n",
       "    </tr>\n",
       "  </tbody>\n",
       "</table>\n",
       "</div>"
      ],
      "text/plain": [
       "              accuracy  precision  recall   f1   roc_auc\n",
       "LogisticReg   0.997283        0.0     0.0  0.0  0.500000\n",
       "DecisionTree  0.996894        0.0     0.0  0.0  0.499805\n",
       "RandomForest  0.997283        0.0     0.0  0.0  0.500000\n",
       "LightGBM      0.997283        0.0     0.0  0.0  0.500000"
      ]
     },
     "execution_count": 83,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "st_time = time.time()\n",
    "\n",
    "results = get_result_pd(models, model_names, X_train, y_train, X_test, y_test)\n",
    "\n",
    "print('Fit time :', time.time() - st_time)\n",
    "results"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# try-1 : sampling"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 86,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "(16000, 25)"
      ]
     },
     "execution_count": 86,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "df = pd.read_csv('./insurance_fraud_detect_data.csv')\n",
    "df.shape"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## 1. 전처리"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### 1-1. 이상치 제거"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "## None"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### 1-2. 차원축소\n",
    "#### feature selection"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "## None"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "#### PCA"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "## None"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### 1-3. train test split"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 87,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "y_train :  (array([0, 1]), array([10276,    27]))\n",
      "y_test : (array([0, 1]), array([2569,    7]))\n",
      "y_eval : (array([0, 1]), array([3114,    7]))\n"
     ]
    }
   ],
   "source": [
    "X_train, X_test, y_train, y_test, X_eval, y_eval = train_valid_test_split(df)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### 1-3. sampling"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 88,
   "metadata": {},
   "outputs": [],
   "source": [
    "from imblearn.over_sampling import RandomOverSampler"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 90,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "(array([0, 1]), array([10276, 10276]))"
      ]
     },
     "execution_count": 90,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "ROS = RandomOverSampler(random_state=13)\n",
    "X_train_over, y_train_over = ROS.fit_resample(X_train, y_train)\n",
    "np.unique(y_train_over, return_counts=True)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 95,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "((10303, 23), (10303,))"
      ]
     },
     "execution_count": 95,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "X_train.shape, y_train.shape"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 96,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "((20552, 23), (20552,))"
      ]
     },
     "execution_count": 96,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "X_train_over.shape, y_train_over.shape"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### 1-4. dummy"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 92,
   "metadata": {
    "scrolled": true
   },
   "outputs": [
    {
     "data": {
      "text/plain": [
       "((20552, 75), (2576, 75), (3121, 75))"
      ]
     },
     "execution_count": 92,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "features = df.columns.drop(['fraud_YN', 'accident_ratio', 'repair_cost', 'insure_cost', 'repair_cnt', 'test_set'])\n",
    "X_train_1hot, X_test_1hot, X_eval_1hot = train_valid_test_dummy(X_train_over, X_test, X_eval, features=features)\n",
    "X_train_1hot.shape, X_test_1hot.shape, X_eval_1hot.shape"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## 2. 학습"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### 2-1. model\n",
    "- Logistic Regression\n",
    "- Decision Tree\n",
    "- Random Forest\n",
    "- LightGBM"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### 2-2. 성능평가\n",
    "- get_clf_eval\n",
    "- print_clf_eval\n",
    "- get_result\n",
    "- get_result_pd"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### 2-3. 학습"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 99,
   "metadata": {},
   "outputs": [
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "/Users/dockyum/opt/anaconda3/lib/python3.8/site-packages/sklearn/metrics/_classification.py:1245: UndefinedMetricWarning: Precision is ill-defined and being set to 0.0 due to no predicted samples. Use `zero_division` parameter to control this behavior.\n",
      "  _warn_prf(average, modifier, msg_start, len(result))\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Fit time : 1.2923731803894043\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "/Users/dockyum/opt/anaconda3/lib/python3.8/site-packages/sklearn/metrics/_classification.py:1245: UndefinedMetricWarning: Precision is ill-defined and being set to 0.0 due to no predicted samples. Use `zero_division` parameter to control this behavior.\n",
      "  _warn_prf(average, modifier, msg_start, len(result))\n"
     ]
    },
    {
     "data": {
      "text/html": [
       "<div>\n",
       "<style scoped>\n",
       "    .dataframe tbody tr th:only-of-type {\n",
       "        vertical-align: middle;\n",
       "    }\n",
       "\n",
       "    .dataframe tbody tr th {\n",
       "        vertical-align: top;\n",
       "    }\n",
       "\n",
       "    .dataframe thead th {\n",
       "        text-align: right;\n",
       "    }\n",
       "</style>\n",
       "<table border=\"1\" class=\"dataframe\">\n",
       "  <thead>\n",
       "    <tr style=\"text-align: right;\">\n",
       "      <th></th>\n",
       "      <th>accuracy</th>\n",
       "      <th>precision</th>\n",
       "      <th>recall</th>\n",
       "      <th>f1</th>\n",
       "      <th>roc_auc</th>\n",
       "    </tr>\n",
       "  </thead>\n",
       "  <tbody>\n",
       "    <tr>\n",
       "      <th>LogisticReg</th>\n",
       "      <td>0.073758</td>\n",
       "      <td>0.002925</td>\n",
       "      <td>1.000000</td>\n",
       "      <td>0.005833</td>\n",
       "      <td>0.535617</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>DecisionTree</th>\n",
       "      <td>0.520575</td>\n",
       "      <td>0.003236</td>\n",
       "      <td>0.571429</td>\n",
       "      <td>0.006436</td>\n",
       "      <td>0.545932</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>RandomForest</th>\n",
       "      <td>0.997283</td>\n",
       "      <td>0.000000</td>\n",
       "      <td>0.000000</td>\n",
       "      <td>0.000000</td>\n",
       "      <td>0.500000</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>LightGBM</th>\n",
       "      <td>0.997283</td>\n",
       "      <td>0.000000</td>\n",
       "      <td>0.000000</td>\n",
       "      <td>0.000000</td>\n",
       "      <td>0.500000</td>\n",
       "    </tr>\n",
       "  </tbody>\n",
       "</table>\n",
       "</div>"
      ],
      "text/plain": [
       "              accuracy  precision    recall        f1   roc_auc\n",
       "LogisticReg   0.073758   0.002925  1.000000  0.005833  0.535617\n",
       "DecisionTree  0.520575   0.003236  0.571429  0.006436  0.545932\n",
       "RandomForest  0.997283   0.000000  0.000000  0.000000  0.500000\n",
       "LightGBM      0.997283   0.000000  0.000000  0.000000  0.500000"
      ]
     },
     "execution_count": 99,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "st_time = time.time()\n",
    "\n",
    "results = get_result_pd(models, model_names, X_train_1hot, y_train_over, X_test_1hot, y_test)\n",
    "\n",
    "print('Fit time :', time.time() - st_time)\n",
    "results"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": []
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python 3",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.8.5"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 4
}
